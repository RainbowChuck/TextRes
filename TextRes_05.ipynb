{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f58d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d747e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vacancies_from_headhunter(query, num_pages=1):\n",
    "    \"\"\"\n",
    "    Функция для сбора вакансий с сайта HeadHunter по запросу.\n",
    "    :param query: Строка запроса (например, 'Python Developer')\n",
    "    :param num_pages: Количество страниц для сбора вакансий\n",
    "    :return: Список вакансий в формате JSON\n",
    "    \"\"\"\n",
    "    base_url = 'https://hh.ru/search/vacancy'\n",
    "    vacancies = []\n",
    "    \n",
    "    for page in range(num_pages):\n",
    "        params = {'text': query, 'page': page}\n",
    "        response = requests.get(base_url, params=params)\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        for vacancy in soup.find_all('div', {'class': 'vacancy-serp-item'}):\n",
    "            title = vacancy.find('a', {'class': 'bloko-link'}).text.strip()\n",
    "            company = vacancy.find('div', {'class': 'vacancy-serp-item__meta-info'}).text.strip()\n",
    "            link = vacancy.find('a', {'class': 'bloko-link'})['href']\n",
    "            \n",
    "            vacancies.append({\n",
    "                'title': title,\n",
    "                'company': company,\n",
    "                'link': link\n",
    "            })\n",
    "    \n",
    "    return vacancies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b46f3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 0.6646 - accuracy: 1.0000 - val_loss: 0.6037 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6281 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5921 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5580 - accuracy: 1.0000 - val_loss: 0.5191 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5247 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4912 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4572 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4232 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3894 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3572 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fbc0bf34880>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример данных для обучения модели\n",
    "resume_texts = [\n",
    "    \"Experienced in Python and Machine Learning\", \n",
    "    \"Expert in AWS and cloud technologies\", \n",
    "    \"Skilled in data analysis and SQL\"\n",
    "]\n",
    "job_descriptions = [\n",
    "    \"Looking for a Python developer with ML expertise\", \n",
    "    \"Hiring for an AWS specialist\", \n",
    "    \"Seeking a SQL data analyst\"\n",
    "]\n",
    "labels = [1, 1, 1]  # Метки, где 1 означает соответствие, а 0 - несоответствие\n",
    "\n",
    "# Преобразование текста в числовые векторы\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(resume_texts + job_descriptions).toarray()\n",
    "\n",
    "# Размерность входного слоя\n",
    "input_dim = X.shape[1]\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels * 2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Модель\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(np.array(X_train), np.array(y_train), epochs=10, batch_size=2, validation_data=(np.array(X_test), np.array(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff38beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_vacancy_match(resume, vacancies):\n",
    "    \"\"\"\n",
    "    Прогнозирует соответствие резюме и вакансий.\n",
    "    :param resume: Текст резюме\n",
    "    :param vacancies: Список вакансий\n",
    "    :return: Список вакансий с их оценками соответствия\n",
    "    \"\"\"\n",
    "    resume_vector = vectorizer.transform([resume]).toarray()\n",
    "    results = []\n",
    "    \n",
    "    for vacancy in vacancies:\n",
    "        vacancy_vector = vectorizer.transform([vacancy['title'] + ' ' + vacancy['company']]).toarray()\n",
    "        match_score = model.predict(np.array([np.concatenate((resume_vector, vacancy_vector))]))\n",
    "        results.append({\n",
    "            'title': vacancy['title'],\n",
    "            'company': vacancy['company'],\n",
    "            'link': vacancy['link'],\n",
    "            'match_score': match_score[0][0]\n",
    "        })\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a9b71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
